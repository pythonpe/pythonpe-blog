<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="es">
  <id>https://blog.python.pe</id>
  <title>Blog de Python Perú | Aprende y explora - Entradas etiquetadas scraping</title>
  <updated>2025-03-17T16:28:48.454395+00:00</updated>
  <link href="https://blog.python.pe"/>
  <link href="https://blog.python.pe/blog/tag/scraping/atom.xml" rel="self"/>
  <generator uri="https://ablog.readthedocs.io/" version="0.11.12">ABlog</generator>
  <subtitle>Explora artículos sobre Python, desarrollo web y más con la comunidad de Python Perú.</subtitle>
  <entry>
    <id>https://blog.python.pe/blog/scraping-con-playwright-y-asyncio/</id>
    <title>Desarrollando un Bot de Scraping Evasivo</title>
    <updated>2024-06-02T00:00:00+00:00</updated>
    <author>
      <name>Jean-Pierre Chauvel</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;En el mundo del scraping, enfrentamos constantemente la batalla contra
mecanismos de defensa diseñados para detectar y bloquear nuestros bots. Hoy,
quiero compartirles un proyecto personal que busca no solo sortear estas
defensas, sino hacerlo de manera eficiente y escalable.&lt;/p&gt;
&lt;p&gt;Al intentar extraer datos de un sitio web que utiliza Radware, un servicio
avanzado contra bots de scraping, me vi en la necesidad de crear una solución
que pudiera superar estos obstáculos. Aquí les presento cómo logré desarrollar
un bot de scraping que no solo logra su cometido sino que evita ser detectado
por mecanismos de anti-bots.&lt;/p&gt;
&lt;/p&gt;
</content>
    <link href="https://blog.python.pe/blog/scraping-con-playwright-y-asyncio/"/>
    <summary>En el mundo del scraping, enfrentamos constantemente la batalla contra
mecanismos de defensa diseñados para detectar y bloquear nuestros bots. Hoy,
quiero compartirles un proyecto personal que busca no solo sortear estas
defensas, sino hacerlo de manera eficiente y escalable.Al intentar extraer datos de un sitio web que utiliza Radware, un servicio
avanzado contra bots de scraping, me vi en la necesidad de crear una solución
que pudiera superar estos obstáculos. Aquí les presento cómo logré desarrollar
un bot de scraping que no solo logra su cometido sino que evita ser detectado
por mecanismos de anti-bots.</summary>
    <category term="asyncio" label="asyncio"/>
    <category term="playwright" label="playwright"/>
    <category term="python" label="python"/>
    <category term="scraping" label="scraping"/>
    <published>2024-06-02T00:00:00+00:00</published>
  </entry>
  <entry>
    <id>https://blog.python.pe/blog/scraping-requests-bs/</id>
    <title>Scraping con Python utilizando la biblioteca requests</title>
    <updated>2024-04-08T00:00:00+00:00</updated>
    <author>
      <name>Jonathan Bolo</name>
    </author>
    <content type="html">&lt;p class="ablog-post-excerpt"&gt;&lt;p&gt;&lt;img alt="Python developer" src="https://blog.python.pe/_images/scraping-requests.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;El scraping web es una técnica poderosa para extraer datos de páginas web de manera automatizada. Python, con su amplio ecosistema de bibliotecas, proporciona herramientas robustas para realizar scraping de manera eficiente. En este artículo, exploraremos cómo utilizar la biblioteca &lt;code class="docutils literal notranslate"&gt;&lt;span class="pre"&gt;requests&lt;/span&gt;&lt;/code&gt; de Python para realizar scraping básico.&lt;/p&gt;
&lt;/p&gt;
</content>
    <link href="https://blog.python.pe/blog/scraping-requests-bs/"/>
    <summary>Python developerEl scraping web es una técnica poderosa para extraer datos de páginas web de manera automatizada. Python, con su amplio ecosistema de bibliotecas, proporciona herramientas robustas para realizar scraping de manera eficiente. En este artículo, exploraremos cómo utilizar la biblioteca requests de Python para realizar scraping básico.</summary>
    <category term="beautifulsoup4" label="beautifulsoup4"/>
    <category term="requests" label="requests"/>
    <category term="scraping" label="scraping"/>
    <category term="utilidades" label="utilidades"/>
    <published>2024-04-08T00:00:00+00:00</published>
  </entry>
</feed>
